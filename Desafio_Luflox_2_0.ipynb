{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMG9ZJOYu6DO1HG0gDHMKnr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CristhianCastro96/BITrepository/blob/main/Desafio_Luflox_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Cargo archivos JSON\n",
        "with open('/content/Candidate Education.json', 'r') as f:\n",
        "    education_data = json.load(f)\n",
        "\n",
        "with open('/content/Candidate Working Experience.json', 'r') as f:\n",
        "    experience_data = json.load(f)\n",
        "\n",
        "with open('/content/Job Description.json', 'r') as f:\n",
        "    job_data = json.load(f)\n",
        "\n",
        "# Convierto educación en DataFrame\n",
        "education_df = pd.json_normalize(education_data['education'])\n",
        "\n",
        "# Convierto experiencia en DataFrame\n",
        "experience_df = pd.json_normalize(\n",
        "    experience_data['experiences'],\n",
        "    'roles',\n",
        "    ['company', 'positionType', 'positionModality']\n",
        ")\n",
        "\n",
        "# Convierto descripción del trabajo en DataFrame\n",
        "job_df = pd.json_normalize(job_data)\n",
        "\n",
        "# Muestro los DataFrames para verificar\n",
        "print(\"DataFrame de Educación:\\n\", education_df)\n",
        "print(\"\\nDataFrame de Experiencia:\\n\", experience_df)\n",
        "print(\"\\nDataFrame de Descripción del Trabajo:\\n\", job_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Jltkxepw3IWV",
        "outputId": "8a3fd155-a137-43f8-ed50-7ab8687558f9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame de Educación:\n",
            "   degree     status               institute  \\\n",
            "0  BA/BS  COMPLETED  Universidad Tecmilenio   \n",
            "\n",
            "                                              career  endDate.seconds  \\\n",
            "0  Mechatronics, Robotics, and Automation Enginee...       1419573600   \n",
            "\n",
            "   endDate.nanoseconds  startDate.seconds  startDate.nanoseconds  \n",
            "0                    0         1262584800                      0  \n",
            "\n",
            "DataFrame de Experiencia:\n",
            "                                role  \\\n",
            "0                   DevOps Engineer   \n",
            "1            Azure DevOps Engineer    \n",
            "2  DevOps Virtualization Specialist   \n",
            "3         Infrastructure Specialist   \n",
            "\n",
            "                                    responsibilities  \\\n",
            "0  [Architecting, building, and improving the sca...   \n",
            "1  [Monitoring and maintaining huge builds of the...   \n",
            "2  [Creating and deploying new virtual redhat mac...   \n",
            "3  [Keeping all infrastructure secure, updating a...   \n",
            "\n",
            "                                         description  startDate.seconds  \\\n",
            "0  Working on a customer service AI multi tenant ...         1672639200   \n",
            "1  Working on an internal repository inside an Az...         1646114400   \n",
            "2  Working on an internal R&D project that focuse...         1488348000   \n",
            "3  Working for the hotel industry supporting the ...         1525150800   \n",
            "\n",
            "   startDate.nanoseconds  endDate.seconds  endDate.nanoseconds  \\\n",
            "0                      0       1703829600                    0   \n",
            "1                      0       1669788000                    0   \n",
            "2                      0       1646114400                    0   \n",
            "3                      0       1559278800                    0   \n",
            "\n",
            "              company positionType positionModality  \n",
            "0              Luflox    FULL-TIME           REMOTE  \n",
            "1         Akvelon INC    FULL-TIME           REMOTE  \n",
            "2  NXP Semiconductors    FULL-TIME           REMOTE  \n",
            "3          IBM Mexico    FULL-TIME           REMOTE  \n",
            "\n",
            "DataFrame de Descripción del Trabajo:\n",
            "                      id                                   responsibilities  \\\n",
            "0  EGTJypSNJtQAB8MIIR8J  [Advocate for the use of cutting-edge technolo...   \n",
            "\n",
            "                                          interviews  status  offerRelocation  \\\n",
            "0  [30-minute screening meeting + 15-minute Engli...  ACTIVE            False   \n",
            "\n",
            "  salary currency paymentFrequency       type  \\\n",
            "0   5000      USD          MONTHLY  FULL-TIME   \n",
            "\n",
            "                                           preferred                    role  \\\n",
            "0  [BS/MS in Computer Science, Engineering, or a ...  Senior Java Developer    \n",
            "\n",
            "                              stack  \\\n",
            "0  [Java, Python, AWS, Spring boot]   \n",
            "\n",
            "                                         description  \\\n",
            "0  We’re looking for a Java Engineer SR to join a...   \n",
            "\n",
            "                                        requirements  isReleasable  \\\n",
            "0  [Strong Client Management experience., Hands-o...         False   \n",
            "\n",
            "   date.seconds  date.nanoseconds  creation.date.seconds  \\\n",
            "0    1713157200                 0             1706018118   \n",
            "\n",
            "   creation.date.nanoseconds       creation.author  \n",
            "0                  837000000  YC2Z1e0Idjjo2kmVuaj1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora quiero conocer el tiempo en años de experiencia."
      ],
      "metadata": {
        "id": "eh3TTw6F9QOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Convierto las columnas de segundos a fechas\n",
        "experience_df['startDate'] = pd.to_datetime(experience_df['startDate.seconds'], unit='s')\n",
        "experience_df['endDate'] = pd.to_datetime(experience_df['endDate.seconds'], unit='s')\n",
        "\n",
        "# Calculo los años de experiencia en cada fila\n",
        "experience_df['experience_years'] = experience_df.apply(\n",
        "    lambda row: (row['endDate'] - row['startDate']).days / 365, axis=1\n",
        ")\n",
        "\n",
        "# Calculo la experiencia total sumando los años de experiencia de cada posición\n",
        "total_experience_years = experience_df['experience_years'].sum()\n",
        "\n",
        "# Muestro el DataFrame con la nueva columna y el total de años de experiencia\n",
        "print(experience_df[['role', 'company', 'startDate', 'endDate', 'experience_years']])\n",
        "print(f\"Total years of experience: {total_experience_years:.2f} years\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kixvJgtG848U",
        "outputId": "d7308807-253a-480d-f803-3f8ac859d607"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                               role             company           startDate  \\\n",
            "0                   DevOps Engineer              Luflox 2023-01-02 06:00:00   \n",
            "1            Azure DevOps Engineer          Akvelon INC 2022-03-01 06:00:00   \n",
            "2  DevOps Virtualization Specialist  NXP Semiconductors 2017-03-01 06:00:00   \n",
            "3         Infrastructure Specialist          IBM Mexico 2018-05-01 05:00:00   \n",
            "\n",
            "              endDate  experience_years  \n",
            "0 2023-12-29 06:00:00          0.989041  \n",
            "1 2022-11-30 06:00:00          0.750685  \n",
            "2 2022-03-01 06:00:00          5.002740  \n",
            "3 2019-05-31 05:00:00          1.082192  \n",
            "Total years of experience: 7.82 years\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora voy a convertir a embedding la descripcion de los trabajos en los que ha estado el candidato, teniendo en cuenta el rol, la descripción y las responsabilidades."
      ],
      "metadata": {
        "id": "dZ_WLMN69Y8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Cargo el modelo preentrenado de Sentence Transformers\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Combino el role, la descripción y las responsabilidades en un solo texto para cada trabajo\n",
        "experience_df['combined_text'] = (\n",
        "    experience_df['role'] + \" \" +\n",
        "    experience_df['description'] + \" \" +\n",
        "    experience_df['responsibilities'].apply(lambda x: ' '.join(x))\n",
        ")\n",
        "\n",
        "# Genero los embeddings\n",
        "embeddings = model.encode(experience_df['combined_text'].tolist())\n",
        "\n",
        "# Convierto los embeddings en un DataFrame para su análisis\n",
        "embeddings_df = pd.DataFrame(embeddings)\n",
        "\n",
        "# Muestro el DataFrame de embeddings\n",
        "print(embeddings_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-55gMvvw-GeI",
        "outputId": "052d6a21-2c0e-4659-8116-b5af97e7bd77"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        0         1         2         3         4         5         6    \\\n",
            "0 -0.004545 -0.044899  0.011999  0.015242 -0.008560 -0.099734 -0.028823   \n",
            "1 -0.011244  0.025386  0.033990  0.007177 -0.042514 -0.061415  0.016476   \n",
            "2 -0.013770  0.025543  0.084357 -0.044327  0.004547 -0.083993 -0.023935   \n",
            "3 -0.001005  0.075701 -0.042829 -0.010030  0.020374 -0.035992  0.081292   \n",
            "\n",
            "        7         8         9    ...       374       375       376       377  \\\n",
            "0 -0.031144 -0.000978  0.012843  ...  0.146548  0.042375  0.026663 -0.048898   \n",
            "1 -0.012981  0.032243  0.108597  ...  0.063074  0.098472  0.009248 -0.062827   \n",
            "2  0.007329 -0.058098  0.024970  ...  0.059904  0.074595 -0.024459  0.004438   \n",
            "3  0.019113 -0.053085 -0.050578  ... -0.003757  0.026270  0.068274 -0.025597   \n",
            "\n",
            "        378       379       380       381       382       383  \n",
            "0  0.126237  0.114810  0.035420 -0.027398 -0.002313  0.003592  \n",
            "1  0.053935  0.140336 -0.001346 -0.034449  0.067301  0.016047  \n",
            "2  0.052823  0.090165 -0.024674 -0.046307  0.036927  0.066683  \n",
            "3  0.081433  0.052272 -0.049044 -0.030756  0.052432 -0.011312  \n",
            "\n",
            "[4 rows x 384 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora hago un Embedding del Job description ue incluya las responsabilidades, preferred, role, stack, description y requirements."
      ],
      "metadata": {
        "id": "Y9nz0nr7BjYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Cargo el modelo preentrenado de Sentence Transformers\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Combino las columnas en job_df: ['responsibilities', 'preferred', 'role', 'stack', 'description', 'requirements']\n",
        "\n",
        "# Función para convertir listas a cadenas\n",
        "def to_string(x):\n",
        "    if isinstance(x, list):\n",
        "        return ' '.join(map(str, x))  # Convertir cada elemento a str y unir\n",
        "    return str(x)  # Si no es lista, convertir a str\n",
        "\n",
        "# Combino todos los campos relevantes en un solo texto\n",
        "job_df['combined_text'] = (\n",
        "    job_df['responsibilities'].apply(to_string) + \" \" +\n",
        "    job_df['preferred'].apply(to_string) + \" \" +\n",
        "    job_df['role'].apply(to_string) + \" \" +\n",
        "    job_df['stack'].apply(to_string) + \" \" +\n",
        "    job_df['description'].apply(to_string) + \" \" +\n",
        "    job_df['requirements'].apply(to_string)\n",
        ")\n",
        "\n",
        "# Genero los embeddings\n",
        "embeddings = model.encode(job_df['combined_text'].tolist())\n",
        "\n",
        "# Convierto los embeddings en un DataFrame para su análisis\n",
        "embeddings_df = pd.DataFrame(embeddings)\n",
        "\n",
        "# Muestro el DataFrame de embeddings\n",
        "print(embeddings_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV5eXNi4_iLF",
        "outputId": "35a773ef-c39d-4c5c-eb30-3861dfe39759"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        0         1         2         3         4         5         6    \\\n",
            "0 -0.067052 -0.011375 -0.000248  0.008052 -0.015139 -0.076249 -0.028596   \n",
            "\n",
            "       7         8         9    ...       374       375       376       377  \\\n",
            "0  0.03672 -0.065317 -0.022223  ...  0.056542  0.060545  0.020345 -0.013978   \n",
            "\n",
            "        378       379       380       381       382       383  \n",
            "0  0.062176  0.107852  0.059268 -0.077877 -0.028277  0.052238  \n",
            "\n",
            "[1 rows x 384 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora tomo los resultados de los dos Embeddings y hago un score que determine el porcentaje en el que el candidato hace match con el job description"
      ],
      "metadata": {
        "id": "qgM59250CsJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Cargo el modelo preentrenado de Sentence Transformers\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Genero embeddings para el candidato (experience_df)\n",
        "candidate_descriptions = experience_df['description'].apply(to_string) + \" \" + experience_df['responsibilities'].apply(to_string)\n",
        "candidate_embeddings = model.encode(candidate_descriptions.tolist())\n",
        "\n",
        "# Genero embeddings para el trabajo (job_df)\n",
        "job_combined_text = (\n",
        "    job_df['responsibilities'].apply(to_string) + \" \" +\n",
        "    job_df['preferred'].apply(to_string) + \" \" +\n",
        "    job_df['role'].apply(to_string) + \" \" +\n",
        "    job_df['stack'].apply(to_string) + \" \" +\n",
        "    job_df['description'].apply(to_string) + \" \" +\n",
        "    job_df['requirements'].apply(to_string)\n",
        ")\n",
        "job_embeddings = model.encode(job_combined_text.tolist())\n",
        "\n",
        "# Calculo la similitud del coseno\n",
        "match_scores = cosine_similarity(candidate_embeddings, job_embeddings)\n",
        "\n",
        "# Calculo el porcentaje de coincidencia\n",
        "# Suponiendo que tomamos el primer candidato y el primer trabajo\n",
        "match_percentage = match_scores[0][0] * 100\n",
        "\n",
        "print(f'Porcentaje de coincidencia entre el candidato y el puesto de trabajo: {match_percentage:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGSdDftiAKdo",
        "outputId": "d31884ac-ea7c-43ca-af88-4c5d501199d8"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Porcentaje de coincidencia entre el candidato y el puesto de trabajo: 62.26%\n"
          ]
        }
      ]
    }
  ]
}